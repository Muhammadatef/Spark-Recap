{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e52f91",
   "metadata": {},
   "source": [
    "### Writing to files\n",
    "- Structured Streaming supports writing streaming query output to files in the same formats as reads. However, it only supports append mode, because while it is easy to write new files in the output directory (i.e., append data to a directory), it is hard to modify existing data files (as would be expected with update and complete modes). It also supports partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fafb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Writing to Memory\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5be397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.readStream.format(\"socket\") \\\n",
    "    .option(\"host\", \"localhost\") \\\n",
    "    .option(\"port\", 12345) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = df.writeStream.outputMode(\"append\") \\\n",
    "    .format(\"memory\")  \\\n",
    "    .queryName('myTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b8646",
   "metadata": {},
   "outputs": [],
   "source": [
    "query= writer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86faa562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "from time import sleep\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    display(query.status)\n",
    "    display(spark.sql('SELECT * FROM myTable').show())\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT * FROM myTable').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ccad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT * FROM myTable').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d052302",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd15f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
