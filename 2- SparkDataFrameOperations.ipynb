{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a4261b-a39c-49f0-a113-0067ebeab3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd91f0f-0c18-4285-b183-1435f7f73e6b",
   "metadata": {},
   "source": [
    "### Inspired by pandas DataFrames in structure, format, and a few specific operations,\n",
    "#### Spark DataFrames are like distributed in-memory tables with named columns and schemas, where each column has a specific data type: integer, string, array, map, real,date, timestamp, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e76555d-8dc5-4879-bfe5-dd51dcfe94ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0fdd28-9206-440a-9911-e85b06e8d86c",
   "metadata": {},
   "source": [
    "### Dealing with missing data with pyspark\n",
    "#### Missing Data\n",
    "1. Keep them.\n",
    "2. Remove them.\n",
    "3. Fill them with some values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93ccff0-b5b3-4338-8328-cf025de7d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('NullData.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8773b714-d6eb-465b-96a6-7ee7ebaa82df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| NULL|\n",
      "|emp2| NULL| NULL|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f53e4bd-a135-443a-8446-6aa4f2d50c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06aa5db-f5cf-4fa6-b331-35eb3701b0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## How to deal with Missin Values in Spark?\n",
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18174509-e7a8-4462-bb29-9c08f5fa6793",
   "metadata": {},
   "source": [
    "#### If specified, drop rows that have less than `thresh` non-null values.\n",
    "#### This overwrites the `how` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e6e5c82-6a9e-451a-9ee3-279361eff85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| NULL|\n",
      "|emp2| NULL| NULL|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.na.drop(thresh=1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "064bc5f7-77b6-4b61-82a8-9b2dab45f807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| NULL|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## thresh=2 means that the row that has at least two values in it\n",
    "df.na.drop(thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff5020f6-3df3-4e73-aaf0-3c37b0819201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## thresh=3 means that the row that has at least 3 values in it\n",
    "\n",
    "df.na.drop(thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9558af58-90e5-4e48-a3e9-a7ce8c930e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(subset=['Sales']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eedb839c-f0a1-4659-93ae-78250ff1f8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(subset=['Name','Sales'], thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f336cd1-3465-4118-adfb-b9a0c0deed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+\n",
      "|  Id|   Name|Sales|\n",
      "+----+-------+-----+\n",
      "|emp1|   John| NULL|\n",
      "|emp2|No Name| NULL|\n",
      "|emp3|No Name|345.0|\n",
      "|emp4|  Cindy|456.0|\n",
      "+----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## how to fill the null values in Spark?\n",
    "\n",
    "df.na.fill('No Name').show()\n",
    "## it went to the string column that has nulls automatically by spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c65501d6-a7da-4e43-b993-dc3e15ec550b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| 25.0|\n",
      "|emp2| NULL| 25.0|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(25).show()\n",
    "## it went to the integer column that has nulls automatically by spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe24e61-87f8-49ad-a80c-e7ea347ed1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| 25.0|\n",
      "|emp2| NULL| 25.0|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(25, subset=['Sales']).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de06d3-e837-41ed-b94f-8bb88972e15a",
   "metadata": {},
   "source": [
    "### DataFrame Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f66ca-0ffa-4da4-a060-648c2d8e2637",
   "metadata": {},
   "source": [
    "In Python, it’s possible to access a DataFrame’s columns either by attribute <b>(df.age)</b> or by indexing <b>(df['age'])</b>. While the former is convenient for interactive data exploration, users are highly encouraged to use the latter form, which is future proof and won’t break with column names that are also attributes on the DataFrame class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfe322f1-71a2-42d8-9e9b-04db22d9576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean \n",
    "mean_value = df.select(mean(df['Sales']).alias('SalesMean')).collect()[0].SalesMean\n",
    "\n",
    "\n",
    "##mean_value = df.select(mean(df['Sales']).alias('SalesMean')).collect()[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "104bfc93-1d3e-4a9d-99e6-def80b95c384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67cc6ff0-9222-421f-9fc7-287c0c5edbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| NULL|400.5|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(mean_value, subset= ['Sales']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12ec2203-2586-480b-9462-78715af6f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sometime in machine learning, you want to transform subset of Spark DF to Pandas DF \n",
    "##to make some feature engineering, here is how to do it \n",
    "df_toPandas = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55479c0d-2ed3-4ee1-8d17-de43539163a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emp1</td>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emp2</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emp3</td>\n",
       "      <td>None</td>\n",
       "      <td>345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emp4</td>\n",
       "      <td>Cindy</td>\n",
       "      <td>456.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id   Name  Sales\n",
       "0  emp1   John    NaN\n",
       "1  emp2   None    NaN\n",
       "2  emp3   None  345.0\n",
       "3  emp4  Cindy  456.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_toPandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f46f57-3c86-48e5-b4a6-97cfbd7a9dfd",
   "metadata": {},
   "source": [
    "## Schemas and Creating DataFrames\n",
    "\n",
    "A schema in Spark defines the column names and associated data types for a DataFrame. Most often, schemas come into play when you are reading structured data\n",
    "from an external data source Defining a schema\n",
    "up front as opposed to taking a schema-on-read approach offers three benefits:\n",
    "<b>\n",
    "1. You relieve Spark from the onus of inferring data types.\n",
    "2. You prevent Spark from creating a separate job just to read a large portion of your file to ascertain the schema, which for a large data file can be expensive and time-consuming.\n",
    "3. You can detect errors early if data doesn’t match the schema.\n",
    "</b>\n",
    "\n",
    "<i>So, it is encouraged to always define your schema up front whenever you want to\n",
    "read a large file from a data source.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffd540ce-33d4-41e4-8829-81f32726c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fire = spark.read.csv('sf-fire-calls.csv', header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0bf8639-6bf7-435d-8049-c92a73ddaf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fire.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cbaea0-0297-4d63-956e-d69fd596c185",
   "metadata": {},
   "source": [
    "#### we are working with BigData, to tell Spark to infer the schema with huge dataset\n",
    "#### it will go to read all the dataset and this may be too much load and processing for Spark\n",
    "#### to solve that, use samplingRatio=0.001 feature, to take only small sample to infer the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d481cfb-1a2c-40ed-9a43-1fe5d1821c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_fire_sample = spark.read.csv('sf-fire-calls.csv', header=True,inferSchema=True, samplingRatio=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fa4dabe-2922-4fee-8fd8-a52f4554b480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: integer (nullable = true)\n",
      " |-- Box: integer (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: integer (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fire_sample.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd9afe41-99c8-4b56-877a-50c40bd20785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('CallNumber', IntegerType(), True), StructField('UnitID', StringType(), True), StructField('IncidentNumber', IntegerType(), True), StructField('CallType', StringType(), True), StructField('CallDate', StringType(), True), StructField('WatchDate', StringType(), True), StructField('CallFinalDisposition', StringType(), True), StructField('AvailableDtTm', StringType(), True), StructField('Address', StringType(), True), StructField('City', StringType(), True), StructField('Zipcode', IntegerType(), True), StructField('Battalion', StringType(), True), StructField('StationArea', IntegerType(), True), StructField('Box', IntegerType(), True), StructField('OriginalPriority', StringType(), True), StructField('Priority', StringType(), True), StructField('FinalPriority', IntegerType(), True), StructField('ALSUnit', BooleanType(), True), StructField('CallTypeGroup', StringType(), True), StructField('NumAlarms', IntegerType(), True), StructField('UnitType', StringType(), True), StructField('UnitSequenceInCallDispatch', IntegerType(), True), StructField('FirePreventionDistrict', StringType(), True), StructField('SupervisorDistrict', IntegerType(), True), StructField('Neighborhood', StringType(), True), StructField('Location', StringType(), True), StructField('RowID', StringType(), True), StructField('Delay', DoubleType(), True)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fire_sample.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f010eb-db78-4eba-9cbb-f0952bbb7a59",
   "metadata": {},
   "source": [
    "#### Now you have the schema from the sample, you can take it and pass to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9154df50-97e6-4914-9d51-9717f79092d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fire = spark.read.csv('sf-fire-calls.csv', header=True,schema=df_fire_sample.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8c414ae-9243-46a6-a3ca-cf7491ac9b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: integer (nullable = true)\n",
      " |-- Box: integer (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: integer (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fire.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3d0d148-a842-4057-9362-ff253c59baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a662e35a-be6a-4fb9-9b7f-41612a0ce86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Medical = df_fire.select('IncidentNumber', 'AvailableDtTm', 'CallType')\\\n",
    "        .where(col('CallType')=='Medical Incident') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e5cfe43-3f0a-4e86-a8b1-ac5d3ce4ca51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+----------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType        |\n",
      "+--------------+----------------------+----------------+\n",
      "|2003241       |01/11/2002 03:01:18 AM|Medical Incident|\n",
      "|2003242       |01/11/2002 02:39:50 AM|Medical Incident|\n",
      "|2003343       |01/11/2002 12:06:57 PM|Medical Incident|\n",
      "|2003348       |01/11/2002 01:08:40 PM|Medical Incident|\n",
      "|2003381       |01/11/2002 03:31:02 PM|Medical Incident|\n",
      "+--------------+----------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Medical.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "254918a6-517f-4aaa-b055-3f9537de90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MedicalNotNull = df_fire.select('IncidentNumber', 'AvailableDtTm', 'CallType')\\\n",
    "        .where(col('CallType').isNotNull()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9dbde12-50f7-4438-bcfe-0d06ea30c68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+\n",
      "|IncidentNumber|       AvailableDtTm|            CallType|\n",
      "+--------------+--------------------+--------------------+\n",
      "|       2003235|01/11/2002 01:51:...|      Structure Fire|\n",
      "|       2003241|01/11/2002 03:01:...|    Medical Incident|\n",
      "|       2003242|01/11/2002 02:39:...|    Medical Incident|\n",
      "|       2003250|01/11/2002 04:16:...|        Vehicle Fire|\n",
      "|       2003259|01/11/2002 06:01:...|              Alarms|\n",
      "|       2003279|01/11/2002 08:03:...|      Structure Fire|\n",
      "|       2003301|01/11/2002 09:46:...|              Alarms|\n",
      "|       2003304|01/11/2002 09:58:...|              Alarms|\n",
      "|       2003343|01/11/2002 12:06:...|    Medical Incident|\n",
      "|       2003348|01/11/2002 01:08:...|    Medical Incident|\n",
      "|       2003381|01/11/2002 03:31:...|    Medical Incident|\n",
      "|       2003382|01/11/2002 02:59:...|      Structure Fire|\n",
      "|       2003399|01/11/2002 04:22:...|    Medical Incident|\n",
      "|       2003403|01/11/2002 04:18:...|    Medical Incident|\n",
      "|       2003408|01/11/2002 04:09:...|      Structure Fire|\n",
      "|       2003408|01/11/2002 04:09:...|      Structure Fire|\n",
      "|       2003408|01/11/2002 04:09:...|      Structure Fire|\n",
      "|       2003409|01/11/2002 04:34:...|    Medical Incident|\n",
      "|       2003417|01/11/2002 04:51:...|    Medical Incident|\n",
      "|       2003417|01/11/2002 04:51:...|    Medical Incident|\n",
      "|       2003429|01/11/2002 05:17:...|Odor (Strange / U...|\n",
      "|       2003435|01/11/2002 05:46:...|    Medical Incident|\n",
      "|       2003453|01/11/2002 06:48:...|              Alarms|\n",
      "|       2003497|01/11/2002 09:03:...|      Structure Fire|\n",
      "|       2003500|01/11/2002 10:08:...|    Medical Incident|\n",
      "|       2003529|01/11/2002 10:56:...|    Medical Incident|\n",
      "|       2003550|01/12/2002 02:04:...|    Medical Incident|\n",
      "|       2003554|01/12/2002 01:56:...|      Structure Fire|\n",
      "|       2003576|01/12/2002 04:17:...|    Medical Incident|\n",
      "|       2003577|01/12/2002 04:23:...|    Medical Incident|\n",
      "+--------------+--------------------+--------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_MedicalNotNull.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e36d7701-c44f-4e6c-a3dc-f36d65c6805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CallDistinct = df_fire.select('CallType')\\\n",
    "        .where(col('CallType').isNotNull()).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "af2c4229-060b-491f-8bc4-db9840257677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            CallType|\n",
      "+--------------------+\n",
      "|Elevator / Escala...|\n",
      "|         Marine Fire|\n",
      "|  Aircraft Emergency|\n",
      "|      Administrative|\n",
      "|              Alarms|\n",
      "|Odor (Strange / U...|\n",
      "|Citizen Assist / ...|\n",
      "|              HazMat|\n",
      "|Watercraft in Dis...|\n",
      "|           Explosion|\n",
      "|           Oil Spill|\n",
      "|        Vehicle Fire|\n",
      "|  Suspicious Package|\n",
      "|Extrication / Ent...|\n",
      "|               Other|\n",
      "|        Outside Fire|\n",
      "|   Traffic Collision|\n",
      "|       Assist Police|\n",
      "|Gas Leak (Natural...|\n",
      "|        Water Rescue|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_CallDistinct.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "49392193-4bac-4615-89d0-36348269fb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------+------+\n",
      "|CallType              |City         |UnitID|\n",
      "+----------------------+-------------+------+\n",
      "|Watercraft in Distress|SF           |E35   |\n",
      "|Watercraft in Distress|SF           |RC1   |\n",
      "|Watercraft in Distress|SF           |E16   |\n",
      "|Watercraft in Distress|PR           |E34   |\n",
      "|Watercraft in Distress|SF           |T08   |\n",
      "|Watercraft in Distress|SF           |E02   |\n",
      "|Watercraft in Distress|SF           |E13   |\n",
      "|Watercraft in Distress|SF           |E28   |\n",
      "|Watercraft in Distress|San Francisco|E35   |\n",
      "|Watercraft in Distress|SF           |FB1   |\n",
      "|Watercraft in Distress|SF           |RB1   |\n",
      "|Watercraft in Distress|TI           |B03   |\n",
      "|Watercraft in Distress|SAN FRANCISCO|B08   |\n",
      "|Watercraft in Distress|FM           |94    |\n",
      "|Watercraft in Distress|San Francisco|B10   |\n",
      "|Watercraft in Distress|San Francisco|RB1   |\n",
      "|Watercraft in Distress|San Francisco|RA48  |\n",
      "|Watercraft in Distress|San Francisco|RS2   |\n",
      "|Watercraft in Distress|SF           |RS1   |\n",
      "|Watercraft in Distress|SF           |RS2   |\n",
      "|Watercraft in Distress|SF           |B01   |\n",
      "|Watercraft in Distress|San Francisco|FB3   |\n",
      "|Water Rescue          |PR           |B11   |\n",
      "|Water Rescue          |SF           |T16   |\n",
      "|Water Rescue          |SF           |E16   |\n",
      "|Water Rescue          |SF           |CR1   |\n",
      "|Water Rescue          |SF           |B08   |\n",
      "|Water Rescue          |PR           |B04   |\n",
      "|Water Rescue          |SF           |E35   |\n",
      "|Water Rescue          |SF           |M08   |\n",
      "|Water Rescue          |PR           |E53   |\n",
      "|Water Rescue          |SF           |E51   |\n",
      "|Water Rescue          |SF           |E13   |\n",
      "|Water Rescue          |SF           |B09   |\n",
      "|Water Rescue          |SF           |B01   |\n",
      "|Water Rescue          |SF           |RS2   |\n",
      "|Water Rescue          |SF           |85    |\n",
      "|Water Rescue          |SF           |M28   |\n",
      "|Water Rescue          |PR           |E14   |\n",
      "|Water Rescue          |SF           |E34   |\n",
      "|Water Rescue          |SF           |M22   |\n",
      "|Water Rescue          |SF           |M43   |\n",
      "|Water Rescue          |SF           |96    |\n",
      "|Water Rescue          |SF           |B07   |\n",
      "|Water Rescue          |SF           |E19   |\n",
      "|Water Rescue          |PR           |E35   |\n",
      "|Water Rescue          |PR           |E18   |\n",
      "|Water Rescue          |SF           |E18   |\n",
      "|Water Rescue          |SF           |66    |\n",
      "|Water Rescue          |SF           |T18   |\n",
      "+----------------------+-------------+------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fire.select('CallType','City','UnitID').where(col('CallType').isNotNull()) \\\n",
    "        .distinct() \\\n",
    "        .sort('CallType', ascending=False) \\\n",
    "        .show(50,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86127504-46db-4ec7-96f6-d64791aab8a3",
   "metadata": {},
   "source": [
    "#### Important Operations for Spark DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b119e585-5782-4893-a3e9-e331f135b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fire2 = df_fire.withColumn('Delay in Seconds', col('Delay') * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4456c6d3-d3f9-4772-b5cc-035bcfa114fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: integer (nullable = true)\n",
      " |-- Box: integer (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: integer (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: double (nullable = true)\n",
      " |-- Delay in Seconds: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fire2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "35a9b1ee-faae-44d7-b6cb-76e992949f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[CallNumber: int, UnitID: string, IncidentNumber: int, CallType: string, CallDate: string, WatchDate: string, CallFinalDisposition: string, AvailableDtTm: string, Address: string, City: string, Zipcode: int, Battalion: string, StationArea: int, Box: int, OriginalPriority: string, Priority: string, FinalPriority: int, ALSUnit: boolean, CallTypeGroup: string, NumAlarms: int, UnitType: string, UnitSequenceInCallDispatch: int, FirePreventionDistrict: string, SupervisorDistrict: int, Neighborhood: string, Location: string, RowID: string, DelayInMins: double, Delay in Seconds: double]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fire2.withColumnRenamed('Delay', 'DelayInMins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b4c1e268-45f8-4a31-b415-55735ab62d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fire_dt = df_fire.withColumn('IncidentDate',to_timestamp(col('CallDate'), 'MM/dd/yyyy')).drop('CallDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "72b2574b-672f-4f07-a3cd-af2dbe2bf4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: integer (nullable = true)\n",
      " |-- Box: integer (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: integer (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: double (nullable = true)\n",
      " |-- IncidentDate: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fire_dt.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ae03b68d-af58-42a1-9dc6-2601d900a57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+-------------------+\n",
      "|        CallType|CallNumber|       IncidentDate|\n",
      "+----------------+----------+-------------------+\n",
      "|Medical Incident|  30010041|2003-01-01 00:00:00|\n",
      "|Medical Incident|  30010045|2003-01-01 00:00:00|\n",
      "|Medical Incident|  30010068|2003-01-01 00:00:00|\n",
      "|          Alarms|  30010080|2003-01-01 00:00:00|\n",
      "|  Structure Fire|  30010086|2003-01-01 00:00:00|\n",
      "|Medical Incident|  30010134|2003-01-01 00:00:00|\n",
      "|          Alarms|  30010135|2003-01-01 00:00:00|\n",
      "|    Vehicle Fire|  30010140|2003-01-01 00:00:00|\n",
      "|Medical Incident|  30010176|2003-01-01 00:00:00|\n",
      "|Medical Incident|  30010226|2003-01-01 00:00:00|\n",
      "|           Other|  30010240|2003-01-01 00:00:00|\n",
      "|Medical Incident|  30010310|2003-01-01 00:00:00|\n",
      "|  Structure Fire|  30010316|2003-01-01 00:00:00|\n",
      "|Medical Incident|  30010348|2003-01-01 00:00:00|\n",
      "|Medical Incident|  30010360|2003-01-01 00:00:00|\n",
      "|Medical Incident|  30010361|2003-01-01 00:00:00|\n",
      "|Medical Incident|  30010377|2003-01-01 00:00:00|\n",
      "|Medical Incident|  30010411|2003-01-01 00:00:00|\n",
      "|Medical Incident|  30010435|2003-01-01 00:00:00|\n",
      "|Medical Incident|  30010446|2003-01-01 00:00:00|\n",
      "+----------------+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fire_dt.select('CallType','CallNumber', 'IncidentDate').where(fn.year('IncidentDate')==2003).alias('IncidentYear').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e31253b9-ed65-4ba0-a229-d776f04ccc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------+\n",
      "|            CallType|CallNumber|IncidentYear|\n",
      "+--------------------+----------+------------+\n",
      "|    Medical Incident|   1040031|        2000|\n",
      "|Citizen Assist / ...|   1040086|        2000|\n",
      "|    Medical Incident|   1040236|        2000|\n",
      "|        Outside Fire|   1040263|        2000|\n",
      "|    Medical Incident|   1050006|        2000|\n",
      "|    Medical Incident|   1050046|        2000|\n",
      "|    Medical Incident|   1050051|        2000|\n",
      "|    Medical Incident|   1050103|        2000|\n",
      "|    Medical Incident|   1050154|        2000|\n",
      "|    Medical Incident|   1050186|        2000|\n",
      "|    Medical Incident|   1050312|        2000|\n",
      "|    Medical Incident|   1050364|        2000|\n",
      "|    Medical Incident|   1050374|        2000|\n",
      "|    Medical Incident|   1060076|        2000|\n",
      "|              Alarms|   1060094|        2000|\n",
      "|    Medical Incident|   1060128|        2000|\n",
      "|      Structure Fire|   1060140|        2000|\n",
      "|               Other|   1060165|        2000|\n",
      "|      Structure Fire|   1060230|        2000|\n",
      "|    Medical Incident|   1060246|        2000|\n",
      "+--------------------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fire_dt.select('CallType','CallNumber',fn.year('IncidentDate').alias('IncidentYear')) \\\n",
    "            .where('IncidentYear=2000') \\\n",
    "            .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8170de3c-49c9-4b92-8527-73038d7f2648",
   "metadata": {},
   "source": [
    "#### Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
